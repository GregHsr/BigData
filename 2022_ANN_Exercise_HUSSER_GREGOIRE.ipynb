{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "dad1ce57-67fb-4b22-bc02-8bd8b7aad9eb",
   "metadata": {
    "tags": []
   },
   "source": [
    " # <strong> Introduction to artificial neural networks </strong>\n",
    " Spring 2023 - Toulouse INP/ENSEEIHT<br /> \n",
    " by Ruming PAN & Mohamed SAADI<br /> \n",
    " Last update: 20-01-2023<br /> \n",
    " \n",
    " This notebook contains three parts:<br />\n",
    " <ol>\n",
    "  <li><strong>Part 1: Building a neural network</strong>, in which a function ```ANN``` builds a DNN (dense neural network) knowing the number of layers (hidden + output), the number of neurons per layer, and given the parameters (weights and biases) for each layer. You are asked to implement an additional activation function (e.g., linear, ReLU) following the example given for the logistic function and test them in new ANN.</li>\n",
    "  <li><strong>Part 2: Training a neural network</strong>, where a set of data \"abalone_data.xlsx\" is given to train a DNN by back-propagating the gradient of a loss function with respect to the network parameters. You are required to do three things: (1) define the training and test datasets, (2) scale the features, and most importantly (3) complete the function ```ANN_backpro``` to successfully run the algorithm. </li>\n",
    "  <li><strong>Part 3: Make your life easier with Keras</strong>, where you are asked to implement a similar DNN using ```keras```, which is a high-level interface for ```TensorFlow```, a famous framework for deep machine learning. The objective here is to present one of the most used libraries in python-based machine learning eco-system. As you will notice, the implementation is very friendly and easy.</li>\n",
    "</ol> \n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96d764ef-555f-4788-a195-a33fdd3767bf",
   "metadata": {
    "tags": []
   },
   "source": [
    "## <strong>Part 1: Building a neural network</strong>\n",
    " In this part, you are required to understand the structure of a neural network and build one given a number of layer ```NL``` and a list of number of neurons per layer ```NpL```."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d8aae1b-d6d9-4cb8-97a9-c9fae30f3fe0",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Step 1: Import libraries, define global functions and hyperparameters"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b14d628-1419-4e93-9930-a70e5f6f87e3",
   "metadata": {},
   "source": [
    "<strong>Task 1:</strong> Based on the example provided for the logistic function, build new activation functions (tanh, ReLU, and linear) in order to use them later for the neural network."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c3523df9-46de-4f00-95be-12eb6bf168d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt \n",
    "import sys\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "\n",
    "## a function that takes a dataframe and returns some basic stastics of its columns\n",
    "def datasum(df):\n",
    "    dfmin = df.apply(np.min, 0)\n",
    "    dfmedian = df.apply(np.median, 0)\n",
    "    dfmean = df.apply(np.mean,0)\n",
    "    dfmax = df.apply(np.max, 0)\n",
    "    dfstd = df.apply(np.std, 0)\n",
    "    dfsummary = pd.DataFrame(np.array([dfmean, dfstd, dfmin, dfmedian, dfmax]), columns=list(df.columns[:]))\n",
    "    dfsummary[\"Statistic\"] = [\"mean\", \"std\", \"min\", \"median\", \"max\"]\n",
    "    xcol = dfsummary.shape[1]\n",
    "    colarr = [dfsummary.columns[xcol-1]]\n",
    "    for item in dfsummary.columns[0:(xcol-1)]:\n",
    "        colarr.append(item)\n",
    "    dfto = dfsummary[colarr]\n",
    "    return dfto\n",
    "\n",
    "## activation functions and their derivatives\n",
    "def logistic(x, mode = \"n\"):\n",
    "    '''\n",
    "    mode = \"n\" : returns f(x)\n",
    "    mode = \"d\": returns f'(x)\n",
    "    '''\n",
    "    t = np.exp(-x)\n",
    "    if mode == \"n\":\n",
    "        fx = 1/(1+t)\n",
    "    if mode == \"d\":\n",
    "        fx = t/(1+t)**2\n",
    "    return fx\n",
    "\n",
    "## define new functions here\n",
    "\n",
    "def tanh(x, mode = \"n\"):\n",
    "    '''\n",
    "    mode = \"n\" : returns f(x)\n",
    "    mode = \"d\": returns f'(x)\n",
    "    '''\n",
    "    p = np.exp(x)\n",
    "    n = np.exp(-x)\n",
    "    if mode == \"n\":\n",
    "        fx = p-n/(p+n)\n",
    "    if mode == \"d\":\n",
    "        fx = 1- (p-n/(p+n))**2\n",
    "    return fx\n",
    "\n",
    "def relu(x, mode = \"n\"):\n",
    "    '''\n",
    "    mode = \"n\" : returns f(x)\n",
    "    mode = \"d\": returns f'(x)\n",
    "    '''\n",
    "    if mode == \"n\":\n",
    "        fx = np.where(x < 0, 0, x)\n",
    "    if mode == \"d\":\n",
    "        fx = np.where(x < 0, 0, x)\n",
    "        fx = np.where(x >= 0, 1, x)\n",
    "    return fx\n",
    "\n",
    "def Linear(x, mode = \"n\"):\n",
    "    '''\n",
    "    mode = \"n\" : returns f(x)\n",
    "    mode = \"d\": returns f'(x)\n",
    "    '''\n",
    "    if mode == \"n\":\n",
    "        fx = x\n",
    "    if mode == \"d\":\n",
    "        fx = 1\n",
    "    return fx"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9756a2c4-d0aa-406c-83e5-7cb7612118f8",
   "metadata": {},
   "source": [
    "#### Hyperparameters: number of layers, size of each layer, and activation function per layer\n",
    "<strong>Indication:</strong> The hyperparameters ```NL```, ```NpL``` and ```Nfx``` are very important throughout the code. They define the number of layers, the number of neurons per each layer, and the number of input features. Always make sure that the size of ```NpL``` and ```ActivFun``` is equal to ```NL```."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f9ad18c0-1f28-4b53-a7ed-d7afc91d3cc5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of neurons per layer:  [3, 1]\n",
      "Number of neurons from the previous layer:  [2, 3]\n"
     ]
    }
   ],
   "source": [
    "## NL is the number of layers including the hidden layers AND the output layer\n",
    "NL = 2\n",
    "## NpL defines the number of neurones per each layer. The length of NpL should be exactly equal to NL\n",
    "NpL = [3, 1]\n",
    "## ActivFun defines the activation functions per each layer\n",
    "ActivFun = ['logistic', 'logistic']\n",
    "\n",
    "## Add the number of features x\n",
    "Nfx = 2\n",
    "## List of size of layers -1: important for automatic definition of parameters\n",
    "NpLm1 = [Nfx]\n",
    "for iL in np.arange(len(NpL)-1):\n",
    "    NpLm1.append(NpL[iL])\n",
    "print(\"Number of neurons per layer: \", NpL)\n",
    "print(\"Number of neurons from the previous layer: \", NpLm1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5534c71d-16a5-4983-91ca-a17eaf93d704",
   "metadata": {},
   "source": [
    "#### Initialization of parameters\n",
    "<strong>Task 2:</strong> Initialize the parameters (weights and biases) using the function ```np.random.rand``` (https://numpy.org/doc/stable/reference/random/generated/numpy.random.rand.html). Convenient initial parameter values should be between -1 and 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f87b7284-6901-4ebb-ad03-7a4f084b38ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3, 2)\n",
      "(3,)\n"
     ]
    }
   ],
   "source": [
    "## List of weights and biases\n",
    "Wts = []\n",
    "bias = []\n",
    "for iL in np.arange(len(NpL)):\n",
    "    ## random initialization\n",
    "    ## the initial parameters should be between -1 and 1\n",
    "    ## use the function np.random.rand to make random initializations (but these will be between 0 and 1)\n",
    "    WL = (np.random.rand(NpL[iL], NpLm1[iL])-0.5)*2\n",
    "    bL = (np.random.rand(NpL[iL])-0.5)*2\n",
    "    ## appending\n",
    "    Wts.append(WL)\n",
    "    bias.append(bL)\n",
    "print(Wts[0].shape)\n",
    "print(bias[0].shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1489f56-3100-4d8d-b896-ec61e8fefd23",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Step 2: Construct the neural network"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2d8ca49-503a-42b0-aff5-8ac97870d7f3",
   "metadata": {},
   "source": [
    "<strong>Task 3:</strong> Complete this function with the equations for each layer to compute the vectors $z_{L}$ and their activation $y_{L} = \\sigma(z_{L})$. The function should return a list ```z``` and a list ```y``` that have ```NpL``` arrays each."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "394fa3c3-b925-4139-94bf-d8926b19a5ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ANN(x, NpL, Nfx, Wts, bias, ActivFun):\n",
    "    '''\n",
    "    This function computes the output of a neural network containing NL layers\n",
    "    where NL is the length of NpL. \n",
    "    o NpL contains the number of neurons per each hidden layer + the output layer. \n",
    "    o Nfx is the number of input features.\n",
    "    o Wts is a list that contains the 2D arrays of weights for each layer.\n",
    "    Each 2D array of weights has dimensions nL x nL-1, nL being the number of neurons\n",
    "    of current layer L, and nL-1 the number of neurons (or features) of layer L-1.\n",
    "    o bias is a list of 1D arrays of weights for each layer.\n",
    "    Each 1D array has dimensions nL x 1. When there are many data points (or members), say\n",
    "    n data points, the bias should be repeated using the function np.tile.\n",
    "    o ActivFun contains the name of the activation function for each layer.\n",
    "    '''\n",
    "    #print('x shape:', x.shape)\n",
    "    #print('NpL:', NpL)\n",
    "    #print('Nfx:', Nfx)\n",
    "    #print('Wts:', len(Wts))\n",
    "\n",
    "    n = x.shape[1]\n",
    "    yLm1 = x\n",
    "\n",
    "    #print('n vaut:', n)\n",
    "    #print('NL vaut:', len(NpL))\n",
    "    \n",
    "    ## z is a list that saves the zL arrays for each hidden and output layer\n",
    "    z = []\n",
    "    ## similarly, y is a list that saves the yL arrays. Specifically, yL[NL-1] contains the output.\n",
    "    y = []\n",
    "    for iL in np.arange(len(NpL)):\n",
    "        ## parameters\n",
    "        WL = Wts[iL]\n",
    "        bL = bias[iL]\n",
    "        ## multiplication\n",
    "        ## make sure that the operation is correct for n individual points.\n",
    "        ## the dimension of zL should be nL x n. Since bL is nL x 1, use np.tile to overcome this issue.\n",
    "        #print('WL shape:', WL.shape)\n",
    "        #print('yLm1 shape:', yLm1.shape)\n",
    "        #print('bL shape:', bL.shape)\n",
    "        \n",
    "        zL = np.dot(WL, yLm1) + np.tile(bL,(n,1)).T\n",
    "        z.append(zL)\n",
    "\n",
    "        #print('zL shape:', zL.shape)\n",
    "        #print('bL shape:', bL.shape)\n",
    "        #print(\"n\",n)\n",
    "\n",
    "        ## activation\n",
    "        ## to call a function given its name, use the function fx = globals()[\"fun_name\"]\n",
    "        sigma = globals()[ActivFun[iL]]\n",
    "        yL = sigma(zL)\n",
    "        y.append(yL)\n",
    "        ## move to next layer\n",
    "        yLm1 = yL\n",
    "    return y,z"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71d5a04e-934c-4581-959a-80a248f88955",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Step 3: Verify that the ANN works for a simple example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "974c4cfb-ec16-4965-bb56-4c58f0ed574f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4, 2)\n",
      "[[0 0]\n",
      " [0 1]\n",
      " [1 0]\n",
      " [1 1]]\n"
     ]
    }
   ],
   "source": [
    "## Input: 4 data points x 2 features (Nfx = 2)\n",
    "input_features = np.array([[0,0], \n",
    "                           [0,1], \n",
    "                           [1,0], \n",
    "                           [1,1]])\n",
    "print(input_features.shape)\n",
    "print(input_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "114e5650-c1ab-45b5-964c-ae5fa86d1049",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4, 1)\n",
      "[[0]\n",
      " [1]\n",
      " [1]\n",
      " [1]]\n"
     ]
    }
   ],
   "source": [
    "# Output: 4 data points x 1 feature\n",
    "target_output = np.array([[0], [1], [1], [1]])\n",
    "print(target_output.shape)\n",
    "print(target_output)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3007438-db04-41c0-b8ff-f8979d623d60",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### Generate outputs for the 4 individuals\n",
    "Run this cell to test your neural network. It should deliver an output ysim of shape (n,1), where n is the number of data points (NOT features)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "1bd5b6d4-42df-4369-b1cb-7c810591382a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4, 1)\n"
     ]
    }
   ],
   "source": [
    "## This where you can test your neural network\n",
    "x_in = input_features.T\n",
    "y,z = ANN(x = x_in, NpL = NpL, Nfx = Nfx, Wts = Wts, bias = bias, ActivFun = ActivFun)\n",
    "ysim = y[NL-1].T\n",
    "print(ysim.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "970e5665-4ef6-4d0f-ac01-b433335d741b",
   "metadata": {},
   "source": [
    "#### Goodness of fit: MSE and RMSE\n",
    "<strong>Task 4:</strong> Complete the equation of MSE and RMSE to estimate the errors of the simulation output of the neural network. Use the matrix product to compute the MSE."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "566beb62-ba89-4d96-9296-0cdb112551d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE =  [[0.22330218]]\n",
      "RMSE =  [[0.4725486]]\n"
     ]
    }
   ],
   "source": [
    "n = target_output.shape[0]\n",
    "MSE = np.dot((target_output - ysim).T,(target_output - ysim))/n\n",
    "print(\"MSE = \", MSE)\n",
    "\n",
    "RMSE = np.sqrt(MSE)\n",
    "print(\"RMSE = \", RMSE)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1342e97d-0aa0-425d-a088-5d56c0e91205",
   "metadata": {},
   "source": [
    "## <strong>Part 2: Training a neural network</strong>\n",
    " In this part, a backpropagation algorithm is implemented to train the neural network."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b60de4bf-e0f8-43e4-b46e-c19178980f89",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Step 1: Read the data, define the training and the test datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81668774-7c27-4b55-bb2d-56c847cb8dec",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### Reading the dataset\n",
    "Any machine learning task involves preparing/preprocessing the data to make it ready for digestion by the machine learning algorithm.\n",
    "\n",
    "At this stage, the data has a 2D shape (lines = individuals or data points, columns = features). The dimensions of the shape of the data help you define the structure of your neural network.\n",
    "\n",
    "The \"abalone_data.xlsx\" dataset that are used for this exercise can be downloaded from https://archive.ics.uci.edu/ml/machine-learning-databases/abalone/. They contain measurements of the following properties of 4177 members of marine snails (<em>haliotis</em>):\n",
    "<ol>\n",
    "  <li><em>Type</em>: male (1), immature (0), female (-1); </li>\n",
    "  <li><em>LongestShell_mm</em>: longest shell measurement in mm; </li>\n",
    "  <li><em>Diameter_mm</em>: length perpendicular to LongestShell in mm;</li>\n",
    "  <li><em>Height_mm</em>: height of the member with meat in shell in mm;</li>\n",
    "  <li><em>WholeWeight_g</em>: mass of the whole abalone in g;</li>\n",
    "  <li><em>ShuckedWeight_g</em>: weight of meat in the abalone in g;</li>  \n",
    "  <li><em>VisceraWeight_g</em>: gut weight of the abalone (after bleeding) in g;</li>\n",
    "  <li><em>ShellWeight_g</em>: weight of the abalone after being dried in g;</li>\n",
    "  <li><em>Age_yr</em>: age of the abalone in years.</li>\n",
    "</ol> \n",
    " \n",
    "The objective of the exercise is to succeed at predicting the age of the abalone knowing its gender, form, and weight."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b042e30d-1c19-4ec6-9a06-cf99eb3998b8",
   "metadata": {},
   "source": [
    "<strong>Task 5:</strong> Complete the first instruction ```pd.read_excel``` to read the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "0fa2512e-0bad-4597-99f8-f38ec666b99f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "</style>\n",
       "<table id=\"T_de2f1\">\n",
       "  <caption>Few lines of the dataset :</caption>\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"blank level0\" >&nbsp;</th>\n",
       "      <th id=\"T_de2f1_level0_col0\" class=\"col_heading level0 col0\" >Type</th>\n",
       "      <th id=\"T_de2f1_level0_col1\" class=\"col_heading level0 col1\" >LongestShell_mm</th>\n",
       "      <th id=\"T_de2f1_level0_col2\" class=\"col_heading level0 col2\" >Diameter_mm</th>\n",
       "      <th id=\"T_de2f1_level0_col3\" class=\"col_heading level0 col3\" >Height_mm</th>\n",
       "      <th id=\"T_de2f1_level0_col4\" class=\"col_heading level0 col4\" >WholeWeight_g</th>\n",
       "      <th id=\"T_de2f1_level0_col5\" class=\"col_heading level0 col5\" >ShuckedWeight_g</th>\n",
       "      <th id=\"T_de2f1_level0_col6\" class=\"col_heading level0 col6\" >VisceraWeight_g</th>\n",
       "      <th id=\"T_de2f1_level0_col7\" class=\"col_heading level0 col7\" >ShellWeight_g</th>\n",
       "      <th id=\"T_de2f1_level0_col8\" class=\"col_heading level0 col8\" >Age_yr</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_de2f1_level0_row0\" class=\"row_heading level0 row0\" >0</th>\n",
       "      <td id=\"T_de2f1_row0_col0\" class=\"data row0 col0\" >1.00</td>\n",
       "      <td id=\"T_de2f1_row0_col1\" class=\"data row0 col1\" >0.46</td>\n",
       "      <td id=\"T_de2f1_row0_col2\" class=\"data row0 col2\" >0.36</td>\n",
       "      <td id=\"T_de2f1_row0_col3\" class=\"data row0 col3\" >0.10</td>\n",
       "      <td id=\"T_de2f1_row0_col4\" class=\"data row0 col4\" >0.51</td>\n",
       "      <td id=\"T_de2f1_row0_col5\" class=\"data row0 col5\" >0.22</td>\n",
       "      <td id=\"T_de2f1_row0_col6\" class=\"data row0 col6\" >0.10</td>\n",
       "      <td id=\"T_de2f1_row0_col7\" class=\"data row0 col7\" >0.15</td>\n",
       "      <td id=\"T_de2f1_row0_col8\" class=\"data row0 col8\" >15.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_de2f1_level0_row1\" class=\"row_heading level0 row1\" >1</th>\n",
       "      <td id=\"T_de2f1_row1_col0\" class=\"data row1 col0\" >1.00</td>\n",
       "      <td id=\"T_de2f1_row1_col1\" class=\"data row1 col1\" >0.35</td>\n",
       "      <td id=\"T_de2f1_row1_col2\" class=\"data row1 col2\" >0.27</td>\n",
       "      <td id=\"T_de2f1_row1_col3\" class=\"data row1 col3\" >0.09</td>\n",
       "      <td id=\"T_de2f1_row1_col4\" class=\"data row1 col4\" >0.23</td>\n",
       "      <td id=\"T_de2f1_row1_col5\" class=\"data row1 col5\" >0.10</td>\n",
       "      <td id=\"T_de2f1_row1_col6\" class=\"data row1 col6\" >0.05</td>\n",
       "      <td id=\"T_de2f1_row1_col7\" class=\"data row1 col7\" >0.07</td>\n",
       "      <td id=\"T_de2f1_row1_col8\" class=\"data row1 col8\" >7.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_de2f1_level0_row2\" class=\"row_heading level0 row2\" >2</th>\n",
       "      <td id=\"T_de2f1_row2_col0\" class=\"data row2 col0\" >-1.00</td>\n",
       "      <td id=\"T_de2f1_row2_col1\" class=\"data row2 col1\" >0.53</td>\n",
       "      <td id=\"T_de2f1_row2_col2\" class=\"data row2 col2\" >0.42</td>\n",
       "      <td id=\"T_de2f1_row2_col3\" class=\"data row2 col3\" >0.14</td>\n",
       "      <td id=\"T_de2f1_row2_col4\" class=\"data row2 col4\" >0.68</td>\n",
       "      <td id=\"T_de2f1_row2_col5\" class=\"data row2 col5\" >0.26</td>\n",
       "      <td id=\"T_de2f1_row2_col6\" class=\"data row2 col6\" >0.14</td>\n",
       "      <td id=\"T_de2f1_row2_col7\" class=\"data row2 col7\" >0.21</td>\n",
       "      <td id=\"T_de2f1_row2_col8\" class=\"data row2 col8\" >9.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_de2f1_level0_row3\" class=\"row_heading level0 row3\" >3</th>\n",
       "      <td id=\"T_de2f1_row3_col0\" class=\"data row3 col0\" >1.00</td>\n",
       "      <td id=\"T_de2f1_row3_col1\" class=\"data row3 col1\" >0.44</td>\n",
       "      <td id=\"T_de2f1_row3_col2\" class=\"data row3 col2\" >0.36</td>\n",
       "      <td id=\"T_de2f1_row3_col3\" class=\"data row3 col3\" >0.12</td>\n",
       "      <td id=\"T_de2f1_row3_col4\" class=\"data row3 col4\" >0.52</td>\n",
       "      <td id=\"T_de2f1_row3_col5\" class=\"data row3 col5\" >0.22</td>\n",
       "      <td id=\"T_de2f1_row3_col6\" class=\"data row3 col6\" >0.11</td>\n",
       "      <td id=\"T_de2f1_row3_col7\" class=\"data row3 col7\" >0.15</td>\n",
       "      <td id=\"T_de2f1_row3_col8\" class=\"data row3 col8\" >10.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_de2f1_level0_row4\" class=\"row_heading level0 row4\" >4</th>\n",
       "      <td id=\"T_de2f1_row4_col0\" class=\"data row4 col0\" >0.00</td>\n",
       "      <td id=\"T_de2f1_row4_col1\" class=\"data row4 col1\" >0.33</td>\n",
       "      <td id=\"T_de2f1_row4_col2\" class=\"data row4 col2\" >0.26</td>\n",
       "      <td id=\"T_de2f1_row4_col3\" class=\"data row4 col3\" >0.08</td>\n",
       "      <td id=\"T_de2f1_row4_col4\" class=\"data row4 col4\" >0.20</td>\n",
       "      <td id=\"T_de2f1_row4_col5\" class=\"data row4 col5\" >0.09</td>\n",
       "      <td id=\"T_de2f1_row4_col6\" class=\"data row4 col6\" >0.04</td>\n",
       "      <td id=\"T_de2f1_row4_col7\" class=\"data row4 col7\" >0.06</td>\n",
       "      <td id=\"T_de2f1_row4_col8\" class=\"data row4 col8\" >7.00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x2d42f801390>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "</style>\n",
       "<table id=\"T_ffd85\">\n",
       "  <caption>Statistics of the dataset</caption>\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th id=\"T_ffd85_level0_col0\" class=\"col_heading level0 col0\" >Statistic</th>\n",
       "      <th id=\"T_ffd85_level0_col1\" class=\"col_heading level0 col1\" >Type</th>\n",
       "      <th id=\"T_ffd85_level0_col2\" class=\"col_heading level0 col2\" >LongestShell_mm</th>\n",
       "      <th id=\"T_ffd85_level0_col3\" class=\"col_heading level0 col3\" >Diameter_mm</th>\n",
       "      <th id=\"T_ffd85_level0_col4\" class=\"col_heading level0 col4\" >Height_mm</th>\n",
       "      <th id=\"T_ffd85_level0_col5\" class=\"col_heading level0 col5\" >WholeWeight_g</th>\n",
       "      <th id=\"T_ffd85_level0_col6\" class=\"col_heading level0 col6\" >ShuckedWeight_g</th>\n",
       "      <th id=\"T_ffd85_level0_col7\" class=\"col_heading level0 col7\" >VisceraWeight_g</th>\n",
       "      <th id=\"T_ffd85_level0_col8\" class=\"col_heading level0 col8\" >ShellWeight_g</th>\n",
       "      <th id=\"T_ffd85_level0_col9\" class=\"col_heading level0 col9\" >Age_yr</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td id=\"T_ffd85_row0_col0\" class=\"data row0 col0\" >mean</td>\n",
       "      <td id=\"T_ffd85_row0_col1\" class=\"data row0 col1\" >0.052909</td>\n",
       "      <td id=\"T_ffd85_row0_col2\" class=\"data row0 col2\" >0.523992</td>\n",
       "      <td id=\"T_ffd85_row0_col3\" class=\"data row0 col3\" >0.407881</td>\n",
       "      <td id=\"T_ffd85_row0_col4\" class=\"data row0 col4\" >0.139516</td>\n",
       "      <td id=\"T_ffd85_row0_col5\" class=\"data row0 col5\" >0.828742</td>\n",
       "      <td id=\"T_ffd85_row0_col6\" class=\"data row0 col6\" >0.359367</td>\n",
       "      <td id=\"T_ffd85_row0_col7\" class=\"data row0 col7\" >0.180594</td>\n",
       "      <td id=\"T_ffd85_row0_col8\" class=\"data row0 col8\" >0.238831</td>\n",
       "      <td id=\"T_ffd85_row0_col9\" class=\"data row0 col9\" >9.933684</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td id=\"T_ffd85_row1_col0\" class=\"data row1 col0\" >std</td>\n",
       "      <td id=\"T_ffd85_row1_col1\" class=\"data row1 col1\" >0.822142</td>\n",
       "      <td id=\"T_ffd85_row1_col2\" class=\"data row1 col2\" >0.120079</td>\n",
       "      <td id=\"T_ffd85_row1_col3\" class=\"data row1 col3\" >0.099228</td>\n",
       "      <td id=\"T_ffd85_row1_col4\" class=\"data row1 col4\" >0.041822</td>\n",
       "      <td id=\"T_ffd85_row1_col5\" class=\"data row1 col5\" >0.490330</td>\n",
       "      <td id=\"T_ffd85_row1_col6\" class=\"data row1 col6\" >0.221936</td>\n",
       "      <td id=\"T_ffd85_row1_col7\" class=\"data row1 col7\" >0.109601</td>\n",
       "      <td id=\"T_ffd85_row1_col8\" class=\"data row1 col8\" >0.139186</td>\n",
       "      <td id=\"T_ffd85_row1_col9\" class=\"data row1 col9\" >3.223783</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td id=\"T_ffd85_row2_col0\" class=\"data row2 col0\" >min</td>\n",
       "      <td id=\"T_ffd85_row2_col1\" class=\"data row2 col1\" >-1.000000</td>\n",
       "      <td id=\"T_ffd85_row2_col2\" class=\"data row2 col2\" >0.075000</td>\n",
       "      <td id=\"T_ffd85_row2_col3\" class=\"data row2 col3\" >0.055000</td>\n",
       "      <td id=\"T_ffd85_row2_col4\" class=\"data row2 col4\" >0.000000</td>\n",
       "      <td id=\"T_ffd85_row2_col5\" class=\"data row2 col5\" >0.002000</td>\n",
       "      <td id=\"T_ffd85_row2_col6\" class=\"data row2 col6\" >0.001000</td>\n",
       "      <td id=\"T_ffd85_row2_col7\" class=\"data row2 col7\" >0.000500</td>\n",
       "      <td id=\"T_ffd85_row2_col8\" class=\"data row2 col8\" >0.001500</td>\n",
       "      <td id=\"T_ffd85_row2_col9\" class=\"data row2 col9\" >1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td id=\"T_ffd85_row3_col0\" class=\"data row3 col0\" >median</td>\n",
       "      <td id=\"T_ffd85_row3_col1\" class=\"data row3 col1\" >0.000000</td>\n",
       "      <td id=\"T_ffd85_row3_col2\" class=\"data row3 col2\" >0.545000</td>\n",
       "      <td id=\"T_ffd85_row3_col3\" class=\"data row3 col3\" >0.425000</td>\n",
       "      <td id=\"T_ffd85_row3_col4\" class=\"data row3 col4\" >0.140000</td>\n",
       "      <td id=\"T_ffd85_row3_col5\" class=\"data row3 col5\" >0.799500</td>\n",
       "      <td id=\"T_ffd85_row3_col6\" class=\"data row3 col6\" >0.336000</td>\n",
       "      <td id=\"T_ffd85_row3_col7\" class=\"data row3 col7\" >0.171000</td>\n",
       "      <td id=\"T_ffd85_row3_col8\" class=\"data row3 col8\" >0.234000</td>\n",
       "      <td id=\"T_ffd85_row3_col9\" class=\"data row3 col9\" >9.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td id=\"T_ffd85_row4_col0\" class=\"data row4 col0\" >max</td>\n",
       "      <td id=\"T_ffd85_row4_col1\" class=\"data row4 col1\" >1.000000</td>\n",
       "      <td id=\"T_ffd85_row4_col2\" class=\"data row4 col2\" >0.815000</td>\n",
       "      <td id=\"T_ffd85_row4_col3\" class=\"data row4 col3\" >0.650000</td>\n",
       "      <td id=\"T_ffd85_row4_col4\" class=\"data row4 col4\" >1.130000</td>\n",
       "      <td id=\"T_ffd85_row4_col5\" class=\"data row4 col5\" >2.825500</td>\n",
       "      <td id=\"T_ffd85_row4_col6\" class=\"data row4 col6\" >1.488000</td>\n",
       "      <td id=\"T_ffd85_row4_col7\" class=\"data row4 col7\" >0.760000</td>\n",
       "      <td id=\"T_ffd85_row4_col8\" class=\"data row4 col8\" >1.005000</td>\n",
       "      <td id=\"T_ffd85_row4_col9\" class=\"data row4 col9\" >29.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x2d42d2dc8e0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df = pd.read_excel(\"abalone_data.xlsx\", sheet_name=\"Sheet1\")\n",
    "display(df.head(5).style.format(\"{0:.2f}\").set_caption(\"Few lines of the dataset :\"))\n",
    "dfsum = datasum(df)\n",
    "pd.options.display.float_format = '{:,.2f}'.format\n",
    "display(dfsum.style.hide(axis = \"index\").set_caption(\"Statistics of the dataset\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa151f77-adf9-44d7-abcf-dd0138ac06d9",
   "metadata": {},
   "source": [
    "#### Training and test datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad7b7b25-91fa-42b1-8199-668c2197ca6f",
   "metadata": {},
   "source": [
    "<strong>Task 6:</strong> After reading the dataset, complete the instructions using ```df.sample``` and ```df.drop``` to split the data into train and test datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "870a38bc-be46-4b48-8b6d-99e0793f23e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "percTrain 0.7000239406272444\n",
      "percTest 0.29997605937275557\n"
     ]
    }
   ],
   "source": [
    "## percentage of data to be used for training\n",
    "percTrain = 0.7\n",
    "\n",
    "## index of training and test\n",
    "#trainindex = np.random.rand(len(df)) < percTrain\n",
    "dftrain = df.sample(frac = percTrain, axis = 0)\n",
    "dftest = df.drop(dftrain.index)\n",
    "\n",
    "print(\"percTrain\",len(dftrain)/len(df))\n",
    "print(\"percTest\",len(dftest)/len(df))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f79be5dc-1211-4f43-a0d5-4c003f50cf03",
   "metadata": {},
   "source": [
    "#### Defining features and output variables"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85a21213-5d5a-48eb-9ccf-0c0b4702365f",
   "metadata": {},
   "source": [
    "<strong>Task 7:</strong> Complete the instructions to define the target/output/dependent variable (age of the abalone) and the attributes/input/independent variables (remaining variables). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "a2686eaf-5431-45fe-9c35-a4423890b367",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "xtrain.head       Type  LongestShell_mm  Diameter_mm  Height_mm  WholeWeight_g  \\\n",
      "520      1             0.21         0.15       0.05           0.04   \n",
      "3039     1             0.57         0.45       0.14           0.95   \n",
      "681      1             0.48         0.37       0.14           0.57   \n",
      "4140    -1             0.65         0.54       0.19           1.24   \n",
      "299      1             0.37         0.28       0.10           0.23   \n",
      "\n",
      "      ShuckedWeight_g  VisceraWeight_g  ShellWeight_g  \n",
      "520              0.02             0.01           0.01  \n",
      "3039             0.40             0.22           0.28  \n",
      "681              0.20             0.14           0.17  \n",
      "4140             0.47             0.24           0.42  \n",
      "299              0.09             0.06           0.07  \n",
      "Shape of original data :  (4177, 9)\n",
      "xtrain :  (2924, 8) ytrain :  (2924,)\n",
      "xtest  :  (1253, 8) ytest  :  (1253,)\n"
     ]
    }
   ],
   "source": [
    "ytrain = dftrain.Age_yr\n",
    "xtrain = dftrain.drop(\"Age_yr\", axis = 1)\n",
    "\n",
    "print(\"xtrain.head\" ,xtrain.head())\n",
    "\n",
    "ytest = dftest.Age_yr\n",
    "xtest = dftest.drop(\"Age_yr\", axis = 1)\n",
    " \n",
    "## printing some information\n",
    "print('Shape of original data : ', df.shape)\n",
    "print('xtrain : ',xtrain.shape, 'ytrain : ',ytrain.shape)\n",
    "print('xtest  : ',xtest.shape,  'ytest  : ',ytest.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0fe48c69-9b0f-425f-9bde-f197b6985645",
   "metadata": {},
   "source": [
    "#### Scaling the data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd11566c-b3bd-402f-a72e-9edac0bcb137",
   "metadata": {},
   "source": [
    "<strong>Task 8:</strong> Estimate the mean and standard deviation for each column/feature from the <ins>train</ins> dataset and use them to scale both the train and the test datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "da817fc5-9145-4ce1-8e01-e681db1ee91c",
   "metadata": {},
   "outputs": [],
   "source": [
    "## estimate the mean and the standard deviation from the train dataset\n",
    "xmean = xtrain.mean()\n",
    "xstd = xtrain.std()\n",
    "## scaling\n",
    "xtrain_scl = (xtrain - xmean)/xstd\n",
    "xtest_scl = (xtest - xmean)/xstd "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "20de3846-0fc6-4bed-bc0b-e3f24db3398a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "</style>\n",
       "<table id=\"T_bff75\">\n",
       "  <caption>Statistics of the dataset - before scaling</caption>\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th id=\"T_bff75_level0_col0\" class=\"col_heading level0 col0\" >Statistic</th>\n",
       "      <th id=\"T_bff75_level0_col1\" class=\"col_heading level0 col1\" >Type</th>\n",
       "      <th id=\"T_bff75_level0_col2\" class=\"col_heading level0 col2\" >LongestShell_mm</th>\n",
       "      <th id=\"T_bff75_level0_col3\" class=\"col_heading level0 col3\" >Diameter_mm</th>\n",
       "      <th id=\"T_bff75_level0_col4\" class=\"col_heading level0 col4\" >Height_mm</th>\n",
       "      <th id=\"T_bff75_level0_col5\" class=\"col_heading level0 col5\" >WholeWeight_g</th>\n",
       "      <th id=\"T_bff75_level0_col6\" class=\"col_heading level0 col6\" >ShuckedWeight_g</th>\n",
       "      <th id=\"T_bff75_level0_col7\" class=\"col_heading level0 col7\" >VisceraWeight_g</th>\n",
       "      <th id=\"T_bff75_level0_col8\" class=\"col_heading level0 col8\" >ShellWeight_g</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td id=\"T_bff75_row0_col0\" class=\"data row0 col0\" >mean</td>\n",
       "      <td id=\"T_bff75_row0_col1\" class=\"data row0 col1\" >0.055062</td>\n",
       "      <td id=\"T_bff75_row0_col2\" class=\"data row0 col2\" >0.524147</td>\n",
       "      <td id=\"T_bff75_row0_col3\" class=\"data row0 col3\" >0.407758</td>\n",
       "      <td id=\"T_bff75_row0_col4\" class=\"data row0 col4\" >0.139983</td>\n",
       "      <td id=\"T_bff75_row0_col5\" class=\"data row0 col5\" >0.828769</td>\n",
       "      <td id=\"T_bff75_row0_col6\" class=\"data row0 col6\" >0.359141</td>\n",
       "      <td id=\"T_bff75_row0_col7\" class=\"data row0 col7\" >0.180659</td>\n",
       "      <td id=\"T_bff75_row0_col8\" class=\"data row0 col8\" >0.238924</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td id=\"T_bff75_row1_col0\" class=\"data row1 col0\" >std</td>\n",
       "      <td id=\"T_bff75_row1_col1\" class=\"data row1 col1\" >0.821674</td>\n",
       "      <td id=\"T_bff75_row1_col2\" class=\"data row1 col2\" >0.120669</td>\n",
       "      <td id=\"T_bff75_row1_col3\" class=\"data row1 col3\" >0.099638</td>\n",
       "      <td id=\"T_bff75_row1_col4\" class=\"data row1 col4\" >0.043308</td>\n",
       "      <td id=\"T_bff75_row1_col5\" class=\"data row1 col5\" >0.489912</td>\n",
       "      <td id=\"T_bff75_row1_col6\" class=\"data row1 col6\" >0.221940</td>\n",
       "      <td id=\"T_bff75_row1_col7\" class=\"data row1 col7\" >0.109902</td>\n",
       "      <td id=\"T_bff75_row1_col8\" class=\"data row1 col8\" >0.138614</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td id=\"T_bff75_row2_col0\" class=\"data row2 col0\" >min</td>\n",
       "      <td id=\"T_bff75_row2_col1\" class=\"data row2 col1\" >-1.000000</td>\n",
       "      <td id=\"T_bff75_row2_col2\" class=\"data row2 col2\" >0.075000</td>\n",
       "      <td id=\"T_bff75_row2_col3\" class=\"data row2 col3\" >0.055000</td>\n",
       "      <td id=\"T_bff75_row2_col4\" class=\"data row2 col4\" >0.000000</td>\n",
       "      <td id=\"T_bff75_row2_col5\" class=\"data row2 col5\" >0.002000</td>\n",
       "      <td id=\"T_bff75_row2_col6\" class=\"data row2 col6\" >0.001000</td>\n",
       "      <td id=\"T_bff75_row2_col7\" class=\"data row2 col7\" >0.000500</td>\n",
       "      <td id=\"T_bff75_row2_col8\" class=\"data row2 col8\" >0.001500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td id=\"T_bff75_row3_col0\" class=\"data row3 col0\" >median</td>\n",
       "      <td id=\"T_bff75_row3_col1\" class=\"data row3 col1\" >0.000000</td>\n",
       "      <td id=\"T_bff75_row3_col2\" class=\"data row3 col2\" >0.545000</td>\n",
       "      <td id=\"T_bff75_row3_col3\" class=\"data row3 col3\" >0.425000</td>\n",
       "      <td id=\"T_bff75_row3_col4\" class=\"data row3 col4\" >0.145000</td>\n",
       "      <td id=\"T_bff75_row3_col5\" class=\"data row3 col5\" >0.800000</td>\n",
       "      <td id=\"T_bff75_row3_col6\" class=\"data row3 col6\" >0.335000</td>\n",
       "      <td id=\"T_bff75_row3_col7\" class=\"data row3 col7\" >0.170000</td>\n",
       "      <td id=\"T_bff75_row3_col8\" class=\"data row3 col8\" >0.235000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td id=\"T_bff75_row4_col0\" class=\"data row4 col0\" >max</td>\n",
       "      <td id=\"T_bff75_row4_col1\" class=\"data row4 col1\" >1.000000</td>\n",
       "      <td id=\"T_bff75_row4_col2\" class=\"data row4 col2\" >0.815000</td>\n",
       "      <td id=\"T_bff75_row4_col3\" class=\"data row4 col3\" >0.650000</td>\n",
       "      <td id=\"T_bff75_row4_col4\" class=\"data row4 col4\" >1.130000</td>\n",
       "      <td id=\"T_bff75_row4_col5\" class=\"data row4 col5\" >2.825500</td>\n",
       "      <td id=\"T_bff75_row4_col6\" class=\"data row4 col6\" >1.488000</td>\n",
       "      <td id=\"T_bff75_row4_col7\" class=\"data row4 col7\" >0.760000</td>\n",
       "      <td id=\"T_bff75_row4_col8\" class=\"data row4 col8\" >1.005000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x2d424e516c0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "</style>\n",
       "<table id=\"T_7d9a6\">\n",
       "  <caption>Statistics of the dataset - after scaling</caption>\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th id=\"T_7d9a6_level0_col0\" class=\"col_heading level0 col0\" >Statistic</th>\n",
       "      <th id=\"T_7d9a6_level0_col1\" class=\"col_heading level0 col1\" >Type</th>\n",
       "      <th id=\"T_7d9a6_level0_col2\" class=\"col_heading level0 col2\" >LongestShell_mm</th>\n",
       "      <th id=\"T_7d9a6_level0_col3\" class=\"col_heading level0 col3\" >Diameter_mm</th>\n",
       "      <th id=\"T_7d9a6_level0_col4\" class=\"col_heading level0 col4\" >Height_mm</th>\n",
       "      <th id=\"T_7d9a6_level0_col5\" class=\"col_heading level0 col5\" >WholeWeight_g</th>\n",
       "      <th id=\"T_7d9a6_level0_col6\" class=\"col_heading level0 col6\" >ShuckedWeight_g</th>\n",
       "      <th id=\"T_7d9a6_level0_col7\" class=\"col_heading level0 col7\" >VisceraWeight_g</th>\n",
       "      <th id=\"T_7d9a6_level0_col8\" class=\"col_heading level0 col8\" >ShellWeight_g</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td id=\"T_7d9a6_row0_col0\" class=\"data row0 col0\" >mean</td>\n",
       "      <td id=\"T_7d9a6_row0_col1\" class=\"data row0 col1\" >0.000000</td>\n",
       "      <td id=\"T_7d9a6_row0_col2\" class=\"data row0 col2\" >0.000000</td>\n",
       "      <td id=\"T_7d9a6_row0_col3\" class=\"data row0 col3\" >0.000000</td>\n",
       "      <td id=\"T_7d9a6_row0_col4\" class=\"data row0 col4\" >0.000000</td>\n",
       "      <td id=\"T_7d9a6_row0_col5\" class=\"data row0 col5\" >-0.000000</td>\n",
       "      <td id=\"T_7d9a6_row0_col6\" class=\"data row0 col6\" >-0.000000</td>\n",
       "      <td id=\"T_7d9a6_row0_col7\" class=\"data row0 col7\" >0.000000</td>\n",
       "      <td id=\"T_7d9a6_row0_col8\" class=\"data row0 col8\" >-0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td id=\"T_7d9a6_row1_col0\" class=\"data row1 col0\" >std</td>\n",
       "      <td id=\"T_7d9a6_row1_col1\" class=\"data row1 col1\" >0.999829</td>\n",
       "      <td id=\"T_7d9a6_row1_col2\" class=\"data row1 col2\" >0.999829</td>\n",
       "      <td id=\"T_7d9a6_row1_col3\" class=\"data row1 col3\" >0.999829</td>\n",
       "      <td id=\"T_7d9a6_row1_col4\" class=\"data row1 col4\" >0.999829</td>\n",
       "      <td id=\"T_7d9a6_row1_col5\" class=\"data row1 col5\" >0.999829</td>\n",
       "      <td id=\"T_7d9a6_row1_col6\" class=\"data row1 col6\" >0.999829</td>\n",
       "      <td id=\"T_7d9a6_row1_col7\" class=\"data row1 col7\" >0.999829</td>\n",
       "      <td id=\"T_7d9a6_row1_col8\" class=\"data row1 col8\" >0.999829</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td id=\"T_7d9a6_row2_col0\" class=\"data row2 col0\" >min</td>\n",
       "      <td id=\"T_7d9a6_row2_col1\" class=\"data row2 col1\" >-1.283819</td>\n",
       "      <td id=\"T_7d9a6_row2_col2\" class=\"data row2 col2\" >-3.721508</td>\n",
       "      <td id=\"T_7d9a6_row2_col3\" class=\"data row2 col3\" >-3.539799</td>\n",
       "      <td id=\"T_7d9a6_row2_col4\" class=\"data row2 col4\" >-3.231742</td>\n",
       "      <td id=\"T_7d9a6_row2_col5\" class=\"data row2 col5\" >-1.687299</td>\n",
       "      <td id=\"T_7d9a6_row2_col6\" class=\"data row2 col6\" >-1.613412</td>\n",
       "      <td id=\"T_7d9a6_row2_col7\" class=\"data row2 col7\" >-1.638983</td>\n",
       "      <td id=\"T_7d9a6_row2_col8\" class=\"data row2 col8\" >-1.712554</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td id=\"T_7d9a6_row3_col0\" class=\"data row3 col0\" >median</td>\n",
       "      <td id=\"T_7d9a6_row3_col1\" class=\"data row3 col1\" >-0.067000</td>\n",
       "      <td id=\"T_7d9a6_row3_col2\" class=\"data row3 col2\" >0.172785</td>\n",
       "      <td id=\"T_7d9a6_row3_col3\" class=\"data row3 col3\" >0.173015</td>\n",
       "      <td id=\"T_7d9a6_row3_col4\" class=\"data row3 col4\" >0.115828</td>\n",
       "      <td id=\"T_7d9a6_row3_col5\" class=\"data row3 col5\" >-0.058713</td>\n",
       "      <td id=\"T_7d9a6_row3_col6\" class=\"data row3 col6\" >-0.108755</td>\n",
       "      <td id=\"T_7d9a6_row3_col7\" class=\"data row3 col7\" >-0.096965</td>\n",
       "      <td id=\"T_7d9a6_row3_col8\" class=\"data row3 col8\" >-0.028302</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td id=\"T_7d9a6_row4_col0\" class=\"data row4 col0\" >max</td>\n",
       "      <td id=\"T_7d9a6_row4_col1\" class=\"data row4 col1\" >1.149819</td>\n",
       "      <td id=\"T_7d9a6_row4_col2\" class=\"data row4 col2\" >2.409931</td>\n",
       "      <td id=\"T_7d9a6_row4_col3\" class=\"data row4 col3\" >2.430808</td>\n",
       "      <td id=\"T_7d9a6_row4_col4\" class=\"data row4 col4\" >22.856222</td>\n",
       "      <td id=\"T_7d9a6_row4_col5\" class=\"data row4 col5\" >4.074997</td>\n",
       "      <td id=\"T_7d9a6_row4_col6\" class=\"data row4 col6\" >5.085466</td>\n",
       "      <td id=\"T_7d9a6_row4_col7\" class=\"data row4 col7\" >5.270531</td>\n",
       "      <td id=\"T_7d9a6_row4_col8\" class=\"data row4 col8\" >5.525761</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x2d42d2dc8e0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "x_train_summary = datasum(xtrain)\n",
    "x_test_summary = datasum(xtest)\n",
    "x_train_scl_summary = datasum(xtrain_scl)\n",
    "x_test_scl_summary = datasum(xtest_scl)\n",
    "## convert to arrays\n",
    "xtrain_scl, ytrain = np.array(xtrain_scl), np.array(ytrain)\n",
    "xtest_scl, ytest = np.array(xtest_scl), np.array(ytest)\n",
    "## print the dataset before and after scaling\n",
    "display(x_train_summary.style.hide(axis = \"index\").set_caption(\"Statistics of the dataset - before scaling\"))\n",
    "display(x_train_scl_summary.style.hide(axis = \"index\").set_caption(\"Statistics of the dataset - after scaling\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ffa1da9-2f7c-42d9-9545-a82495751e05",
   "metadata": {},
   "source": [
    "### Step 2: Build the backpropagation algorithm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d1a2149-4fb3-4ddb-adb7-2078324fecbe",
   "metadata": {},
   "source": [
    "<strong>Task 9:</strong> Complete the following function to train the neural network using the gradient descent method based on backpropagation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "fe91295f-036a-4c83-9075-2498dfaa53b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ANN_backpro(x, ytrue, NpL, Nfx, Wts, bias, ActivFun, lr):\n",
    "    '''\n",
    "    o Shape of x: Nfx * n, where n is the number of data points, and Nfx the number of features\n",
    "    o Shape of ytrue: n * 1, where n is the number of data points.\n",
    "    \n",
    "    '''\n",
    "    #print(\"x\",x.shape)\n",
    "    #print(\"ytrue\",ytrue.shape)\n",
    "    \n",
    "    ## step 1: feed forward\n",
    "    n = x.shape[1]\n",
    "    yLm1 = x\n",
    "    z = []\n",
    "    y = []\n",
    "    for iL in np.arange(len(NpL)):\n",
    "        ## get the parameters for the current layer\n",
    "        WL = Wts[iL]\n",
    "        bL = bias[iL]\n",
    "        ## estimate zL from yLm1\n",
    "        zL = np.dot(WL, yLm1) + np.tile(bL,(n,1)).T\n",
    "        z.append(zL)\n",
    "        #print(\"zL\",zL.shape)\n",
    "\n",
    "        ## estimate yL from zL\n",
    "        sigma = globals()[ActivFun[iL]]\n",
    "        #print(\"sigma\",sigma)\n",
    "        yL = sigma(zL, mode = \"n\")\n",
    "        y.append(yL)\n",
    "\n",
    "        ## update yLm1\n",
    "        yLm1 = yL\n",
    "\n",
    "    ## step 2: backpropagation\n",
    "    ytrue = ytrue.T\n",
    "    dJ_dy = 2*(yL[-1] - ytrue)                                          ####### crochets en trop??\n",
    "\n",
    "    for iL in reversed(np.arange(len(NpL))):\n",
    "        print(\"iL\",iL)\n",
    "        ## getting zL of the current layer\n",
    "        zL = z[iL]\n",
    "\n",
    "        ## estimating dJ_dz from dJ_dy\n",
    "        sigma = globals()[ActivFun[iL]]\n",
    "        dJ_dz = dJ_dy * sigma(zL, mode = \"d\")\n",
    "\n",
    "        ## getting the parameters of current layer\n",
    "        WL = Wts[iL]\n",
    "        bL = bias[iL]\n",
    "       \n",
    "        ## estimating dJ_dW from dJ_dz\n",
    "        ## dJ_dz : (nL x n)\n",
    "        ## yLm1 : (nL-1 x n)\n",
    "        ## getting yL-1\n",
    "        if iL == 0:\n",
    "            yLm1 = x\n",
    "        else:\n",
    "            yLm1 = y[iL-1]\n",
    "\n",
    "        dJ_dW = np.dot(dJ_dz, yLm1.T)\n",
    "        \n",
    "        #print(\"dJ_dz\",dJ_dz.shape, \"nL x n\")\n",
    "        #print(\"yLm1\",yLm1.shape, \"nL-1 x n\")\n",
    "\n",
    "        # estimating dJ_db from dJ_dz\n",
    "        # J_db : nL x 1\n",
    "        # dJ_dz : nL x n\n",
    "        dJ_db = np.dot(dJ_dz, np.ones((n,1)))\n",
    "\n",
    "        #print(\"dJ_db\",dJ_db.shape, \"nL x 1\")\n",
    "        #print(\"dJ_dz\",dJ_dz.shape, \"nL x n\")\n",
    "\n",
    "        ## backpropagating the gradient from layer L to layer L-1\n",
    "        ## WL : nL x nL-1\n",
    "        ## dJ_dz : nL x n\n",
    "        ## dJ_dy (L-1) : nL-1 x n\n",
    "        dJ_dy = np.dot(WL.T, dJ_dz)\n",
    "\n",
    "        #print(\"WL\",WL.shape, \"nL x nL-1\")\n",
    "        #print(\"dJ_dz\",dJ_dz.shape, \"nL x n\")\n",
    "        #print(\"dJ_dy\",dJ_dy.shape, \"nL-1 x n\")\n",
    "        #print(\"dJ_dW\",dJ_dW.shape, \"nL x nL-1\")\n",
    "        #print(\"bL\",bL.shape, \"nL x 1\",\"avant\")\n",
    "        ## Updating the parameters\n",
    "        #print(type(np.multiply(dJ_db,lr)))\n",
    "\n",
    "        WL = WL - np.multiply(dJ_dW,lr)\n",
    "        bL = bL - np.multiply(dJ_db,lr).T\n",
    "        #print(\"WL\",WL.shape, \"nL x nL-1\")\n",
    "        #print(\"bL\",bL.shape, \"nL x 1\",\"apres\")\n",
    "        Wts[iL] = WL\n",
    "        bias[iL] = bL\n",
    "    return Wts, bias"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8c3927e-e855-4dda-9272-c4453f22c6a9",
   "metadata": {},
   "source": [
    "<strong>Task 10:</strong> Complete the initialization of parameters (exactly the same as in part 1)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "4d082f3a-ec71-4502-95af-6e52d8c4412a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of neurons per layer:  [6, 1]\n",
      "Number of neurons from the previous layer:  [8, 6]\n"
     ]
    }
   ],
   "source": [
    "## NL is the number of layers including the hidden layers AND the output layer\n",
    "NL = 2\n",
    "## NpL defines the number of neurones per each layer. The length of NpL should be exactly equal to NL\n",
    "NpL = [6,1]\n",
    "## Add the number of features x\n",
    "Nfx = 8\n",
    "## ActivFun defines the activation functions per each layer\n",
    "#ActivFun = ['logistic', 'relu']\n",
    "ActivFun = ['relu', 'relu']\n",
    "\n",
    "## List of size of layers -1: important for automatic definition of parameters\n",
    "NpLm1 = [Nfx]\n",
    "for iL in np.arange(len(NpL)-1):\n",
    "    NpLm1.append(NpL[iL])\n",
    "print(\"Number of neurons per layer: \", NpL)\n",
    "print(\"Number of neurons from the previous layer: \", NpLm1)\n",
    "\n",
    "## Learning rate\n",
    "lr = 0.001\n",
    "\n",
    "## Number of epochs\n",
    "epochs = 50\n",
    "\n",
    "## List of weights and biases\n",
    "Wts = []\n",
    "bias = []\n",
    "for iL in np.arange(len(NpL)):\n",
    "    ## random initialization\n",
    "    WL = (np.random.rand(NpL[iL], NpLm1[iL])-0.5)*2\n",
    "    bL = (np.random.rand(NpL[iL])-0.5)*2\n",
    "    ## appending\n",
    "    Wts.append(WL)\n",
    "    bias.append(bL)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e75e783-8bbc-4fdd-85ca-45edd9a9e8e0",
   "metadata": {},
   "source": [
    "<strong>Task 11:</strong> Complete the following lines in order to keep track of (1) epochs, (2) training error (MSE), and (3) test error."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "91a36fc6-aeec-4a24-8318-48283781d217",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Learning rate:  0.001   Number of epochs:  50\n",
      "iL 1\n",
      "iL 0\n",
      "Epoch: 00001/00050 Training error: 0.0  Test error: 0.08iL 1\n",
      "iL 0\n",
      "Epoch: 00002/00050 Training error: 0.0  Test error: 0.08iL 1\n",
      "iL 0\n",
      "Epoch: 00003/00050 Training error: 0.0  Test error: 0.08iL 1\n",
      "iL 0\n",
      "Epoch: 00004/00050 Training error: 0.0  Test error: 0.08iL 1\n",
      "iL 0\n",
      "Epoch: 00005/00050 Training error: nan  Test error: naniL 1\n",
      "iL 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\grego\\AppData\\Local\\Temp\\ipykernel_10392\\3066921389.py:44: RuntimeWarning: overflow encountered in multiply\n",
      "  dJ_dz = dJ_dy * sigma(zL, mode = \"d\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 00006/00050 Training error: nan  Test error: naniL 1\n",
      "iL 0\n",
      "Epoch: 00007/00050 Training error: nan  Test error: naniL 1\n",
      "iL 0\n",
      "Epoch: 00008/00050 Training error: nan  Test error: naniL 1\n",
      "iL 0\n",
      "Epoch: 00009/00050 Training error: nan  Test error: naniL 1\n",
      "iL 0\n",
      "Epoch: 00010/00050 Training error: nan  Test error: naniL 1\n",
      "iL 0\n",
      "Epoch: 00011/00050 Training error: nan  Test error: naniL 1\n",
      "iL 0\n",
      "Epoch: 00012/00050 Training error: nan  Test error: naniL 1\n",
      "iL 0\n",
      "Epoch: 00013/00050 Training error: nan  Test error: naniL 1\n",
      "iL 0\n",
      "Epoch: 00014/00050 Training error: nan  Test error: naniL 1\n",
      "iL 0\n",
      "Epoch: 00015/00050 Training error: nan  Test error: naniL 1\n",
      "iL 0\n",
      "Epoch: 00016/00050 Training error: nan  Test error: naniL 1\n",
      "iL 0\n",
      "Epoch: 00017/00050 Training error: nan  Test error: naniL 1\n",
      "iL 0\n",
      "Epoch: 00018/00050 Training error: nan  Test error: naniL 1\n",
      "iL 0\n",
      "Epoch: 00019/00050 Training error: nan  Test error: naniL 1\n",
      "iL 0\n",
      "Epoch: 00020/00050 Training error: nan  Test error: naniL 1\n",
      "iL 0\n",
      "Epoch: 00021/00050 Training error: nan  Test error: naniL 1\n",
      "iL 0\n",
      "Epoch: 00022/00050 Training error: nan  Test error: naniL 1\n",
      "iL 0\n",
      "Epoch: 00023/00050 Training error: nan  Test error: naniL 1\n",
      "iL 0\n",
      "Epoch: 00024/00050 Training error: nan  Test error: naniL 1\n",
      "iL 0\n",
      "Epoch: 00025/00050 Training error: nan  Test error: naniL 1\n",
      "iL 0\n",
      "Epoch: 00026/00050 Training error: nan  Test error: naniL 1\n",
      "iL 0\n",
      "Epoch: 00027/00050 Training error: nan  Test error: naniL 1\n",
      "iL 0\n",
      "Epoch: 00028/00050 Training error: nan  Test error: naniL 1\n",
      "iL 0\n",
      "Epoch: 00029/00050 Training error: nan  Test error: naniL 1\n",
      "iL 0\n",
      "Epoch: 00030/00050 Training error: nan  Test error: naniL 1\n",
      "iL 0\n",
      "Epoch: 00031/00050 Training error: nan  Test error: naniL 1\n",
      "iL 0\n",
      "Epoch: 00032/00050 Training error: nan  Test error: naniL 1\n",
      "iL 0\n",
      "Epoch: 00033/00050 Training error: nan  Test error: naniL 1\n",
      "iL 0\n",
      "Epoch: 00034/00050 Training error: nan  Test error: naniL 1\n",
      "iL 0\n",
      "Epoch: 00035/00050 Training error: nan  Test error: naniL 1\n",
      "iL 0\n",
      "Epoch: 00036/00050 Training error: nan  Test error: naniL 1\n",
      "iL 0\n",
      "Epoch: 00037/00050 Training error: nan  Test error: naniL 1\n",
      "iL 0\n",
      "Epoch: 00038/00050 Training error: nan  Test error: naniL 1\n",
      "iL 0\n",
      "Epoch: 00039/00050 Training error: nan  Test error: naniL 1\n",
      "iL 0\n",
      "Epoch: 00040/00050 Training error: nan  Test error: naniL 1\n",
      "iL 0\n",
      "Epoch: 00041/00050 Training error: nan  Test error: naniL 1\n",
      "iL 0\n",
      "Epoch: 00042/00050 Training error: nan  Test error: naniL 1\n",
      "iL 0\n",
      "Epoch: 00043/00050 Training error: nan  Test error: naniL 1\n",
      "iL 0\n",
      "Epoch: 00044/00050 Training error: nan  Test error: naniL 1\n",
      "iL 0\n",
      "Epoch: 00045/00050 Training error: nan  Test error: naniL 1\n",
      "iL 0\n",
      "Epoch: 00046/00050 Training error: nan  Test error: naniL 1\n",
      "iL 0\n",
      "Epoch: 00047/00050 Training error: nan  Test error: naniL 1\n",
      "iL 0\n",
      "Epoch: 00048/00050 Training error: nan  Test error: naniL 1\n",
      "iL 0\n",
      "Epoch: 00049/00050 Training error: nan  Test error: naniL 1\n",
      "iL 0\n",
      "Epoch: 00050/00050 Training error: nan  Test error: nan"
     ]
    }
   ],
   "source": [
    "print(\"Learning rate: \", lr, \"  Number of epochs: \", epochs)\n",
    "MSEtrain = np.array([])\n",
    "MSEtest = np.array([])\n",
    "epoch = np.array([])\n",
    "sys.stdout.write('\\r')\n",
    "for iepoch in np.arange(epochs):\n",
    "    epoch = np.append(epoch, iepoch)\n",
    "    ## train the neural network\n",
    "    x_in = xtrain_scl.T \n",
    "    Wts, bias = ANN_backpro(x = x_in, ytrue = ytrain, NpL = NpL, Nfx = Nfx, Wts = Wts, bias = bias, ActivFun = ActivFun, lr = lr)\n",
    "\n",
    "    #print(\"Wts[0]\", Wts[0].shape)\n",
    "    #print(\"Wts[1]\", Wts[1].shape)\n",
    "\n",
    "    ## estimate the MSE for the train dataset\n",
    "    x_in = xtrain_scl.T\n",
    "    #print(\"x_in\",x_in.shape)\n",
    "    yout, zout = ANN(x = x_in, NpL = NpL, Nfx = Nfx, Wts = Wts, bias = bias, ActivFun = ActivFun)\n",
    "    ytrainsim = yout\n",
    "    #print(yout)\n",
    "    ntrain = ytrain.shape[0]\n",
    "    #print(\"ytrainsim\",len(ytrainsim))\n",
    "    #print(\"ytrain\",ytrain.shape)\n",
    "    Error_train = np.dot((ytrain - ytrainsim[-1]).T,(ytrain - ytrainsim[-1]))/ntrain\n",
    "    \n",
    "    ## estimate the MSE for the test dataset\n",
    "    x_in = xtest_scl.T\n",
    "    yout, zout = ANN(x = x_in, NpL = NpL, Nfx = Nfx, Wts = Wts, bias = bias, ActivFun = ActivFun)\n",
    "    ytestsim = yout\n",
    "    ntest = ytest.shape[0]\n",
    "    Error_test = np.dot((ytest - ytestsim[-1]).T,(ytest - ytestsim[-1]))/ntest\n",
    "    \n",
    "    ## keeping track of the errors\n",
    "    MSEtrain = np.append(MSEtrain, Error_train[0,0])\n",
    "    MSEtest = np.append(MSEtest, Error_test[0,0]) \n",
    "    \n",
    "    ## print the evolution\n",
    "    sys.stdout.write('\\r' \"Epoch: \" + str(int(iepoch + 1)).rjust(5,'0') + \"/\"\n",
    "                    + str(int(epochs)).rjust(5,'0') + \" \" +\n",
    "                    \"Training error: \" + str(round(Error_train[0,0],2)) + \n",
    "                    \"  Test error: \" + str(round(Error_test[0,0],2)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29ab8eb3-e3ca-4573-9041-347e5ab30ce1",
   "metadata": {},
   "source": [
    "Now, we can see the evolution of the training and test errors across the epochs. Note that only the RMSE (in years) is plotted."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "a917284a-2611-425a-93f6-44e6a4609b8f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1000x500 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "## initialization of the plot\n",
    "plt.grid(color='black', axis='y', linestyle='-', linewidth=0.5)    \n",
    "plt.grid(color='black', axis='x', linestyle='-', linewidth=0.5)   \n",
    "plt.grid(which='minor',color='grey', axis='x', linestyle=':', linewidth=0.5)     \n",
    "plt.grid(which='minor',color='grey', axis='y', linestyle=':', linewidth=0.5)    \n",
    "plt.xticks(fontsize=16); plt.yticks(fontsize=16)   \n",
    "plt.xlabel('epoch',fontsize=16 )\n",
    "plt.ylabel(r'$RMSE_{train}$ (yr), $RMSE_{test}$ (yr)', size = 16)\n",
    "## plotting the data\n",
    "plt.plot(epoch, MSEtrain**0.5, color = \"blue\", linewidth = 2., label = \"Training error\")\n",
    "plt.plot(epoch, MSEtest**0.5, color = \"orange\", linewidth = 2., label = \"Test error\")\n",
    "plt.title(\"Prediction error\", fontsize = 16)\n",
    "plt.gcf().set_size_inches(10, 5)\n",
    "plt.legend(loc=\"upper right\", prop={'size': 15})\n",
    "plt.savefig(\"fig01.png\", dpi = 300,  bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3acbd929-abc0-45f4-bc9b-a37a9959e4c5",
   "metadata": {},
   "source": [
    "<strong>Task 12:</strong> Complete the code to compute the outputs on the test dataset using the optimized parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "62ddcb1a-64d8-4921-aadd-92a9de3edf89",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "setting an array element with a sequence. The requested array has an inhomogeneous shape after 1 dimensions. The detected shape was (2,) + inhomogeneous part.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[29], line 16\u001b[0m\n\u001b[0;32m     14\u001b[0m plt\u001b[38;5;241m.\u001b[39mylabel(\u001b[38;5;124mr\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m$Age_\u001b[39m\u001b[38;5;132;01m{sim}\u001b[39;00m\u001b[38;5;124m$ (yr)\u001b[39m\u001b[38;5;124m'\u001b[39m,fontsize\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m16\u001b[39m )\n\u001b[0;32m     15\u001b[0m \u001b[38;5;66;03m## plotting the data\u001b[39;00m\n\u001b[1;32m---> 16\u001b[0m \u001b[43mplt\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mscatter\u001b[49m\u001b[43m(\u001b[49m\u001b[43mytest\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mytestsim\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcolor\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mred\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmarker\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mo\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m     17\u001b[0m plt\u001b[38;5;241m.\u001b[39mplot([\u001b[38;5;241m0.\u001b[39m, \u001b[38;5;241m30.\u001b[39m], [\u001b[38;5;241m0.\u001b[39m, \u001b[38;5;241m30.\u001b[39m], color\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mk\u001b[39m\u001b[38;5;124m'\u001b[39m, linestyle\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m-\u001b[39m\u001b[38;5;124m'\u001b[39m, linewidth\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m)\n\u001b[0;32m     18\u001b[0m plt\u001b[38;5;241m.\u001b[39mgcf()\u001b[38;5;241m.\u001b[39mset_size_inches(\u001b[38;5;241m6\u001b[39m, \u001b[38;5;241m6\u001b[39m)\n",
      "File \u001b[1;32m~\\Documents\\ENSEEIHT\\BigData\\tp_ann\\lib\\site-packages\\matplotlib\\pyplot.py:2798\u001b[0m, in \u001b[0;36mscatter\u001b[1;34m(x, y, s, c, marker, cmap, norm, vmin, vmax, alpha, linewidths, edgecolors, plotnonfinite, data, **kwargs)\u001b[0m\n\u001b[0;32m   2793\u001b[0m \u001b[38;5;129m@_copy_docstring_and_deprecators\u001b[39m(Axes\u001b[38;5;241m.\u001b[39mscatter)\n\u001b[0;32m   2794\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mscatter\u001b[39m(\n\u001b[0;32m   2795\u001b[0m         x, y, s\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, c\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, marker\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, cmap\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, norm\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m   2796\u001b[0m         vmin\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, vmax\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, alpha\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, linewidths\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;241m*\u001b[39m,\n\u001b[0;32m   2797\u001b[0m         edgecolors\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, plotnonfinite\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m, data\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m-> 2798\u001b[0m     __ret \u001b[38;5;241m=\u001b[39m gca()\u001b[38;5;241m.\u001b[39mscatter(\n\u001b[0;32m   2799\u001b[0m         x, y, s\u001b[38;5;241m=\u001b[39ms, c\u001b[38;5;241m=\u001b[39mc, marker\u001b[38;5;241m=\u001b[39mmarker, cmap\u001b[38;5;241m=\u001b[39mcmap, norm\u001b[38;5;241m=\u001b[39mnorm,\n\u001b[0;32m   2800\u001b[0m         vmin\u001b[38;5;241m=\u001b[39mvmin, vmax\u001b[38;5;241m=\u001b[39mvmax, alpha\u001b[38;5;241m=\u001b[39malpha, linewidths\u001b[38;5;241m=\u001b[39mlinewidths,\n\u001b[0;32m   2801\u001b[0m         edgecolors\u001b[38;5;241m=\u001b[39medgecolors, plotnonfinite\u001b[38;5;241m=\u001b[39mplotnonfinite,\n\u001b[0;32m   2802\u001b[0m         \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m({\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdata\u001b[39m\u001b[38;5;124m\"\u001b[39m: data} \u001b[38;5;28;01mif\u001b[39;00m data \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m {}), \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   2803\u001b[0m     sci(__ret)\n\u001b[0;32m   2804\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m __ret\n",
      "File \u001b[1;32m~\\Documents\\ENSEEIHT\\BigData\\tp_ann\\lib\\site-packages\\matplotlib\\__init__.py:1433\u001b[0m, in \u001b[0;36m_preprocess_data.<locals>.inner\u001b[1;34m(ax, data, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1430\u001b[0m \u001b[38;5;129m@functools\u001b[39m\u001b[38;5;241m.\u001b[39mwraps(func)\n\u001b[0;32m   1431\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21minner\u001b[39m(ax, \u001b[38;5;241m*\u001b[39margs, data\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m   1432\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m data \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m-> 1433\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m func(ax, \u001b[38;5;241m*\u001b[39m\u001b[38;5;28mmap\u001b[39m(sanitize_sequence, args), \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1435\u001b[0m     bound \u001b[38;5;241m=\u001b[39m new_sig\u001b[38;5;241m.\u001b[39mbind(ax, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1436\u001b[0m     auto_label \u001b[38;5;241m=\u001b[39m (bound\u001b[38;5;241m.\u001b[39marguments\u001b[38;5;241m.\u001b[39mget(label_namer)\n\u001b[0;32m   1437\u001b[0m                   \u001b[38;5;129;01mor\u001b[39;00m bound\u001b[38;5;241m.\u001b[39mkwargs\u001b[38;5;241m.\u001b[39mget(label_namer))\n",
      "File \u001b[1;32m~\\Documents\\ENSEEIHT\\BigData\\tp_ann\\lib\\site-packages\\matplotlib\\axes\\_axes.py:4524\u001b[0m, in \u001b[0;36mAxes.scatter\u001b[1;34m(self, x, y, s, c, marker, cmap, norm, vmin, vmax, alpha, linewidths, edgecolors, plotnonfinite, **kwargs)\u001b[0m\n\u001b[0;32m   4521\u001b[0m \u001b[38;5;66;03m# np.ma.ravel yields an ndarray, not a masked array,\u001b[39;00m\n\u001b[0;32m   4522\u001b[0m \u001b[38;5;66;03m# unless its argument is a masked array.\u001b[39;00m\n\u001b[0;32m   4523\u001b[0m x \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mma\u001b[38;5;241m.\u001b[39mravel(x)\n\u001b[1;32m-> 4524\u001b[0m y \u001b[38;5;241m=\u001b[39m \u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mma\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mravel\u001b[49m\u001b[43m(\u001b[49m\u001b[43my\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   4525\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m x\u001b[38;5;241m.\u001b[39msize \u001b[38;5;241m!=\u001b[39m y\u001b[38;5;241m.\u001b[39msize:\n\u001b[0;32m   4526\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mx and y must be the same size\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32m~\\Documents\\ENSEEIHT\\BigData\\tp_ann\\lib\\site-packages\\numpy\\ma\\core.py:6840\u001b[0m, in \u001b[0;36m_frommethod.__call__\u001b[1;34m(self, a, *args, **params)\u001b[0m\n\u001b[0;32m   6837\u001b[0m     args \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(args)\n\u001b[0;32m   6838\u001b[0m     a, args[\u001b[38;5;241m0\u001b[39m] \u001b[38;5;241m=\u001b[39m args[\u001b[38;5;241m0\u001b[39m], a\n\u001b[1;32m-> 6840\u001b[0m marr \u001b[38;5;241m=\u001b[39m \u001b[43masanyarray\u001b[49m\u001b[43m(\u001b[49m\u001b[43ma\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   6841\u001b[0m method_name \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\n\u001b[0;32m   6842\u001b[0m method \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mgetattr\u001b[39m(\u001b[38;5;28mtype\u001b[39m(marr), method_name, \u001b[38;5;28;01mNone\u001b[39;00m)\n",
      "File \u001b[1;32m~\\Documents\\ENSEEIHT\\BigData\\tp_ann\\lib\\site-packages\\numpy\\ma\\core.py:8120\u001b[0m, in \u001b[0;36masanyarray\u001b[1;34m(a, dtype)\u001b[0m\n\u001b[0;32m   8118\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(a, MaskedArray) \u001b[38;5;129;01mand\u001b[39;00m (dtype \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mor\u001b[39;00m dtype \u001b[38;5;241m==\u001b[39m a\u001b[38;5;241m.\u001b[39mdtype):\n\u001b[0;32m   8119\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m a\n\u001b[1;32m-> 8120\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mmasked_array\u001b[49m\u001b[43m(\u001b[49m\u001b[43ma\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcopy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkeep_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msubok\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\Documents\\ENSEEIHT\\BigData\\tp_ann\\lib\\site-packages\\numpy\\ma\\core.py:2820\u001b[0m, in \u001b[0;36mMaskedArray.__new__\u001b[1;34m(cls, data, mask, dtype, copy, subok, ndmin, fill_value, keep_mask, hard_mask, shrink, order)\u001b[0m\n\u001b[0;32m   2811\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m   2812\u001b[0m \u001b[38;5;124;03mCreate a new masked array from scratch.\u001b[39;00m\n\u001b[0;32m   2813\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   2817\u001b[0m \n\u001b[0;32m   2818\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m   2819\u001b[0m \u001b[38;5;66;03m# Process data.\u001b[39;00m\n\u001b[1;32m-> 2820\u001b[0m _data \u001b[38;5;241m=\u001b[39m \u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43marray\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcopy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcopy\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2821\u001b[0m \u001b[43m                 \u001b[49m\u001b[43morder\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43morder\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msubok\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mndmin\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mndmin\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   2822\u001b[0m _baseclass \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mgetattr\u001b[39m(data, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m_baseclass\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;28mtype\u001b[39m(_data))\n\u001b[0;32m   2823\u001b[0m \u001b[38;5;66;03m# Check that we're not erasing the mask.\u001b[39;00m\n",
      "\u001b[1;31mValueError\u001b[0m: setting an array element with a sequence. The requested array has an inhomogeneous shape after 1 dimensions. The detected shape was (2,) + inhomogeneous part."
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "## Showing the results for the test dataset\n",
    "x_in = xtest_scl.T\n",
    "yout, zout = ANN(x = x_in, NpL = NpL, Nfx = Nfx, Wts = Wts, bias = bias, ActivFun = ActivFun)\n",
    "ytestsim = yout\n",
    "Error_test = np.dot((ytest - ytestsim[0]).T,(ytest - ytestsim[0]))/ntest\n",
    "## Making a scatter plot\n",
    "## initialization of the plot\n",
    "plt.grid(color='black', axis='y', linestyle='-', linewidth=0.5)    \n",
    "plt.grid(color='black', axis='x', linestyle='-', linewidth=0.5)   \n",
    "plt.grid(which='minor',color='grey', axis='x', linestyle=':', linewidth=0.5)     \n",
    "plt.grid(which='minor',color='grey', axis='y', linestyle=':', linewidth=0.5)    \n",
    "plt.xticks(fontsize=16); plt.yticks(fontsize=16)   \n",
    "plt.xlabel(r'$Age_{obs}$ (yr)',fontsize=16 )\n",
    "plt.ylabel(r'$Age_{sim}$ (yr)',fontsize=16 )\n",
    "## plotting the data\n",
    "plt.scatter(ytest, ytestsim, color = \"red\", marker = \"o\")\n",
    "plt.plot([0., 30.], [0., 30.], color='k', linestyle='-', linewidth=2)\n",
    "plt.gcf().set_size_inches(6, 6)\n",
    "plt.savefig(\"fig02.png\", dpi = 300,  bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fcf23d2a-355f-4269-9007-e059cfe4a7d1",
   "metadata": {},
   "source": [
    "## <strong>Part 3: Make your life easier with Keras</strong>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6fac845-9b3c-46a7-b3d1-cebf25f94e0a",
   "metadata": {},
   "source": [
    "In this part, an implementation of a DNN using functions from Keras is shown."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ff88e48-d89c-410b-b456-50399d21c3b5",
   "metadata": {},
   "source": [
    "### Step 1: Build the ANN architecture using Keras"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7759ba1c-824b-4b79-9246-39f3cf54ec70",
   "metadata": {},
   "source": [
    "<strong>Task 13:</strong> Modify the following function to implement the same ANN as the one implemented in Part 2."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "d365ca70-94e2-4806-8636-ae1aba182817",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ANN_keras(shape):\n",
    "  \n",
    "  model = keras.models.Sequential()\n",
    "  model.add(keras.layers.Input(shape, name=\"InputLayer\"))\n",
    "  model.add(keras.layers.Dense(6, activation='sigmoid', name='HiddenLayer01'))\n",
    "  model.add(keras.layers.Dense(1, activation='sigmoid', name='HiddenLayer02'))\n",
    "  model.add(keras.layers.Dense(1, name='Output'))\n",
    "  \n",
    "  model.compile(optimizer = 'adam',\n",
    "                loss      = 'mse',\n",
    "                metrics   = ['mae', 'mse'] )\n",
    "  return model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd13627a-f857-49fd-bd4e-2e658d475628",
   "metadata": {},
   "source": [
    "The following lines help create and instantiate an ANN using the function ```ANN_keras```.\n",
    "\n",
    "<strong>Task 14:</strong> Use ```Nfx``` to create a \"copy\" of the ANN defined using ```ANN_keras```."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "9b572375-3211-406c-830e-66b6ed49c0a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " HiddenLayer01 (Dense)       (None, 6)                 54        \n",
      "                                                                 \n",
      " HiddenLayer02 (Dense)       (None, 1)                 7         \n",
      "                                                                 \n",
      " Output (Dense)              (None, 1)                 2         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 63\n",
      "Trainable params: 63\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model= ANN_keras( (Nfx,) )\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f279dd64-51f1-443e-be11-744617509b70",
   "metadata": {},
   "source": [
    "### Step 2: Train and evaluate the model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8df30be7-f04e-45de-8ce4-80298793b713",
   "metadata": {},
   "source": [
    "Now, the model is ready for training. The following function launches the training of the ANN network."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "b0d22521-ceb5-4f33-94f9-21abf60d973b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "366/366 [==============================] - 1s 3ms/step - loss: 77.0834 - mae: 8.1515 - mse: 77.0834 - val_loss: 68.4458 - val_mae: 7.6413 - val_mse: 68.4458\n",
      "Epoch 2/50\n",
      "366/366 [==============================] - 1s 2ms/step - loss: 62.5719 - mae: 7.2186 - mse: 62.5719 - val_loss: 57.1017 - val_mae: 6.8587 - val_mse: 57.1017\n",
      "Epoch 3/50\n",
      "366/366 [==============================] - 1s 2ms/step - loss: 52.5833 - mae: 6.4937 - mse: 52.5833 - val_loss: 48.1404 - val_mae: 6.1726 - val_mse: 48.1404\n",
      "Epoch 4/50\n",
      "366/366 [==============================] - 1s 2ms/step - loss: 44.4216 - mae: 5.8397 - mse: 44.4216 - val_loss: 40.6406 - val_mae: 5.5409 - val_mse: 40.6406\n",
      "Epoch 5/50\n",
      "366/366 [==============================] - 1s 2ms/step - loss: 37.5541 - mae: 5.2397 - mse: 37.5541 - val_loss: 34.3131 - val_mae: 4.9497 - val_mse: 34.3131\n",
      "Epoch 6/50\n",
      "366/366 [==============================] - 1s 2ms/step - loss: 31.7560 - mae: 4.6932 - mse: 31.7560 - val_loss: 28.9862 - val_mae: 4.4229 - val_mse: 28.9862\n",
      "Epoch 7/50\n",
      "366/366 [==============================] - 1s 2ms/step - loss: 26.8962 - mae: 4.1847 - mse: 26.8962 - val_loss: 24.5492 - val_mae: 3.9427 - val_mse: 24.5492\n",
      "Epoch 8/50\n",
      "366/366 [==============================] - 1s 2ms/step - loss: 22.8806 - mae: 3.7482 - mse: 22.8806 - val_loss: 20.9065 - val_mae: 3.5398 - val_mse: 20.9065\n",
      "Epoch 9/50\n",
      "366/366 [==============================] - 1s 2ms/step - loss: 19.6056 - mae: 3.3596 - mse: 19.6056 - val_loss: 17.9475 - val_mae: 3.1862 - val_mse: 17.9475\n",
      "Epoch 10/50\n",
      "366/366 [==============================] - 1s 2ms/step - loss: 16.9854 - mae: 3.0582 - mse: 16.9854 - val_loss: 15.6165 - val_mae: 2.9149 - val_mse: 15.6165\n",
      "Epoch 11/50\n",
      "366/366 [==============================] - 1s 2ms/step - loss: 14.9589 - mae: 2.7971 - mse: 14.9589 - val_loss: 13.8407 - val_mae: 2.6727 - val_mse: 13.8407\n",
      "Epoch 12/50\n",
      "366/366 [==============================] - 1s 2ms/step - loss: 13.4331 - mae: 2.6131 - mse: 13.4331 - val_loss: 12.5245 - val_mae: 2.5568 - val_mse: 12.5245\n",
      "Epoch 13/50\n",
      "366/366 [==============================] - 1s 2ms/step - loss: 12.3238 - mae: 2.4953 - mse: 12.3238 - val_loss: 11.5913 - val_mae: 2.4531 - val_mse: 11.5913\n",
      "Epoch 14/50\n",
      "366/366 [==============================] - 1s 2ms/step - loss: 11.5627 - mae: 2.3886 - mse: 11.5627 - val_loss: 10.9670 - val_mae: 2.3736 - val_mse: 10.9670\n",
      "Epoch 15/50\n",
      "366/366 [==============================] - 1s 2ms/step - loss: 11.0789 - mae: 2.3524 - mse: 11.0789 - val_loss: 10.5811 - val_mae: 2.3694 - val_mse: 10.5811\n",
      "Epoch 16/50\n",
      "366/366 [==============================] - 1s 2ms/step - loss: 10.7920 - mae: 2.3583 - mse: 10.7920 - val_loss: 10.3619 - val_mae: 2.3659 - val_mse: 10.3619\n",
      "Epoch 17/50\n",
      "366/366 [==============================] - 1s 2ms/step - loss: 10.6281 - mae: 2.3567 - mse: 10.6281 - val_loss: 10.2358 - val_mae: 2.3628 - val_mse: 10.2358\n",
      "Epoch 18/50\n",
      "366/366 [==============================] - 1s 2ms/step - loss: 10.5374 - mae: 2.3569 - mse: 10.5374 - val_loss: 10.1648 - val_mae: 2.3591 - val_mse: 10.1648\n",
      "Epoch 19/50\n",
      "366/366 [==============================] - 1s 2ms/step - loss: 10.4620 - mae: 2.3525 - mse: 10.4620 - val_loss: 10.0481 - val_mae: 2.3447 - val_mse: 10.0481\n",
      "Epoch 20/50\n",
      "366/366 [==============================] - 1s 2ms/step - loss: 9.9871 - mae: 2.2673 - mse: 9.9871 - val_loss: 9.0415 - val_mae: 2.1544 - val_mse: 9.0415\n",
      "Epoch 21/50\n",
      "366/366 [==============================] - 1s 2ms/step - loss: 8.8071 - mae: 2.0491 - mse: 8.8071 - val_loss: 8.0087 - val_mae: 1.9660 - val_mse: 8.0087\n",
      "Epoch 22/50\n",
      "366/366 [==============================] - 1s 2ms/step - loss: 8.0395 - mae: 1.9417 - mse: 8.0395 - val_loss: 7.4169 - val_mae: 1.9017 - val_mse: 7.4169\n",
      "Epoch 23/50\n",
      "366/366 [==============================] - 1s 2ms/step - loss: 7.6102 - mae: 1.9106 - mse: 7.6102 - val_loss: 7.0772 - val_mae: 1.8610 - val_mse: 7.0772\n",
      "Epoch 24/50\n",
      "366/366 [==============================] - 1s 2ms/step - loss: 7.3688 - mae: 1.8893 - mse: 7.3688 - val_loss: 6.8755 - val_mae: 1.8536 - val_mse: 6.8755\n",
      "Epoch 25/50\n",
      "366/366 [==============================] - 1s 2ms/step - loss: 7.2268 - mae: 1.8821 - mse: 7.2268 - val_loss: 6.7564 - val_mae: 1.8363 - val_mse: 6.7564\n",
      "Epoch 26/50\n",
      "366/366 [==============================] - 1s 2ms/step - loss: 7.1365 - mae: 1.8790 - mse: 7.1365 - val_loss: 6.6750 - val_mae: 1.8547 - val_mse: 6.6750\n",
      "Epoch 27/50\n",
      "366/366 [==============================] - 1s 2ms/step - loss: 7.0758 - mae: 1.8949 - mse: 7.0758 - val_loss: 6.6290 - val_mae: 1.8386 - val_mse: 6.6290\n",
      "Epoch 28/50\n",
      "366/366 [==============================] - 1s 2ms/step - loss: 7.0343 - mae: 1.8972 - mse: 7.0343 - val_loss: 6.5933 - val_mae: 1.8387 - val_mse: 6.5933\n",
      "Epoch 29/50\n",
      "366/366 [==============================] - 1s 2ms/step - loss: 7.0034 - mae: 1.8926 - mse: 7.0034 - val_loss: 6.5561 - val_mae: 1.8482 - val_mse: 6.5561\n",
      "Epoch 30/50\n",
      "366/366 [==============================] - 1s 2ms/step - loss: 6.9725 - mae: 1.8955 - mse: 6.9725 - val_loss: 6.5240 - val_mae: 1.8579 - val_mse: 6.5240\n",
      "Epoch 31/50\n",
      "366/366 [==============================] - 1s 2ms/step - loss: 6.9435 - mae: 1.8962 - mse: 6.9435 - val_loss: 6.5004 - val_mae: 1.8523 - val_mse: 6.5004\n",
      "Epoch 32/50\n",
      "366/366 [==============================] - 1s 2ms/step - loss: 6.9190 - mae: 1.8945 - mse: 6.9190 - val_loss: 6.4727 - val_mae: 1.8559 - val_mse: 6.4727\n",
      "Epoch 33/50\n",
      "366/366 [==============================] - 1s 2ms/step - loss: 6.8877 - mae: 1.8887 - mse: 6.8877 - val_loss: 6.4516 - val_mae: 1.8745 - val_mse: 6.4516\n",
      "Epoch 34/50\n",
      "366/366 [==============================] - 1s 2ms/step - loss: 6.8647 - mae: 1.8944 - mse: 6.8647 - val_loss: 6.4339 - val_mae: 1.8421 - val_mse: 6.4339\n",
      "Epoch 35/50\n",
      "366/366 [==============================] - 1s 2ms/step - loss: 6.8389 - mae: 1.8855 - mse: 6.8389 - val_loss: 6.4050 - val_mae: 1.8473 - val_mse: 6.4050\n",
      "Epoch 36/50\n",
      "366/366 [==============================] - 1s 2ms/step - loss: 6.8120 - mae: 1.8819 - mse: 6.8120 - val_loss: 6.3872 - val_mae: 1.8333 - val_mse: 6.3872\n",
      "Epoch 37/50\n",
      "366/366 [==============================] - 1s 2ms/step - loss: 6.7824 - mae: 1.8778 - mse: 6.7824 - val_loss: 6.3635 - val_mae: 1.8268 - val_mse: 6.3635\n",
      "Epoch 38/50\n",
      "366/366 [==============================] - 1s 2ms/step - loss: 6.7509 - mae: 1.8700 - mse: 6.7509 - val_loss: 6.3330 - val_mae: 1.8275 - val_mse: 6.3330\n",
      "Epoch 39/50\n",
      "366/366 [==============================] - 1s 2ms/step - loss: 6.7171 - mae: 1.8612 - mse: 6.7171 - val_loss: 6.3015 - val_mae: 1.8227 - val_mse: 6.3015\n",
      "Epoch 40/50\n",
      "366/366 [==============================] - 1s 2ms/step - loss: 6.6861 - mae: 1.8610 - mse: 6.6861 - val_loss: 6.2703 - val_mae: 1.8189 - val_mse: 6.2703\n",
      "Epoch 41/50\n",
      "366/366 [==============================] - 1s 2ms/step - loss: 6.6496 - mae: 1.8544 - mse: 6.6496 - val_loss: 6.2408 - val_mae: 1.8069 - val_mse: 6.2408\n",
      "Epoch 42/50\n",
      "366/366 [==============================] - 1s 2ms/step - loss: 6.6147 - mae: 1.8446 - mse: 6.6147 - val_loss: 6.2021 - val_mae: 1.8091 - val_mse: 6.2021\n",
      "Epoch 43/50\n",
      "366/366 [==============================] - 1s 2ms/step - loss: 6.5685 - mae: 1.8372 - mse: 6.5685 - val_loss: 6.1645 - val_mae: 1.8131 - val_mse: 6.1645\n",
      "Epoch 44/50\n",
      "366/366 [==============================] - 1s 2ms/step - loss: 6.5351 - mae: 1.8354 - mse: 6.5351 - val_loss: 6.1323 - val_mae: 1.7944 - val_mse: 6.1323\n",
      "Epoch 45/50\n",
      "366/366 [==============================] - 1s 2ms/step - loss: 6.4868 - mae: 1.8256 - mse: 6.4868 - val_loss: 6.0978 - val_mae: 1.7882 - val_mse: 6.0978\n",
      "Epoch 46/50\n",
      "366/366 [==============================] - 1s 2ms/step - loss: 6.4385 - mae: 1.8136 - mse: 6.4385 - val_loss: 6.0428 - val_mae: 1.8057 - val_mse: 6.0428\n",
      "Epoch 47/50\n",
      "366/366 [==============================] - 1s 2ms/step - loss: 6.3940 - mae: 1.8142 - mse: 6.3940 - val_loss: 6.0012 - val_mae: 1.7778 - val_mse: 6.0012\n",
      "Epoch 48/50\n",
      "366/366 [==============================] - 1s 2ms/step - loss: 6.3367 - mae: 1.7979 - mse: 6.3367 - val_loss: 5.9539 - val_mae: 1.7899 - val_mse: 5.9539\n",
      "Epoch 49/50\n",
      "366/366 [==============================] - 1s 2ms/step - loss: 6.2877 - mae: 1.8003 - mse: 6.2877 - val_loss: 5.9214 - val_mae: 1.7432 - val_mse: 5.9214\n",
      "Epoch 50/50\n",
      "366/366 [==============================] - 1s 2ms/step - loss: 6.2460 - mae: 1.7847 - mse: 6.2460 - val_loss: 5.8704 - val_mae: 1.7382 - val_mse: 5.8704\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(xtrain,\n",
    "                    ytrain,\n",
    "                    epochs          = 50,\n",
    "                    batch_size      = xtrain.shape[1],\n",
    "                    validation_data = (xtest, ytest))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "552f2dab-fec3-4497-94a2-a1460c8f02dc",
   "metadata": {},
   "source": [
    "The test scores are computed using the optimized parameter set on the test dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "dd647516-9782-44a6-831a-f3d1d220d3d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test / loss      : 11.6285\n",
      "test / mae       : 2.7330\n",
      "test / mse       : 11.6285\n"
     ]
    }
   ],
   "source": [
    "score = model.evaluate(xtest_scl, ytest, verbose=0)\n",
    "\n",
    "print('test / loss      : {:5.4f}'.format(score[0]))\n",
    "print('test / mae       : {:5.4f}'.format(score[1]))\n",
    "print('test / mse       : {:5.4f}'.format(score[2]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2bbe857-d3fd-48da-a9dc-a75e686f8b68",
   "metadata": {},
   "source": [
    "We can make a prediction with the Keras-built ANN and compare it with that from your own ANN."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "f17b3e22-cd95-4261-bd58-acef44622bc3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 8)\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "predicted age using Keras-built network:  5.37 yr\n",
      "predicted age using your neural network:  nan yr\n"
     ]
    }
   ],
   "source": [
    "mydata = [ 1, 0.3, 0.1, 0.2, 0.2, 0.5, 0.7, -1. ]\n",
    "mydata = np.array(mydata).reshape(1,8)\n",
    "print(mydata.shape)\n",
    "predictions = model.predict(mydata)\n",
    "print(\"predicted age using Keras-built network: \", round(predictions[0,0],2), \"yr\")\n",
    "yout, zout = ANN(x = mydata.T, NpL = NpL, Nfx = Nfx, Wts = Wts, bias = bias, ActivFun = ActivFun)\n",
    "print(\"predicted age using your neural network: \", round(yout[NL-1][0,0], 2), \"yr\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e237b49-85bd-475d-b536-3cfc4f1f67b0",
   "metadata": {},
   "source": [
    "Finally, we can use parameters estimated by Keras and your neural network to test whether you get the same estimates."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "4813e857-e6b8-4da4-92df-d8f406849736",
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "list index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[58], line 8\u001b[0m\n\u001b[0;32m      6\u001b[0m NpL_Keras \u001b[38;5;241m=\u001b[39m [\u001b[38;5;241m16\u001b[39m,\u001b[38;5;241m32\u001b[39m,\u001b[38;5;241m16\u001b[39m,\u001b[38;5;241m1\u001b[39m]\n\u001b[0;32m      7\u001b[0m Nfx \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m8\u001b[39m\n\u001b[1;32m----> 8\u001b[0m yout_k, zout_k \u001b[38;5;241m=\u001b[39m \u001b[43mANN\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mmydata\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mT\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mNpL\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mNpL_Keras\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mNfx\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mNfx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mWts\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mwts_keras\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbias\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mbias_keras\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mActivFun\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mActivFun_Keras\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      9\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpredicted age using Keras-built network: \u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28mround\u001b[39m(predictions[\u001b[38;5;241m0\u001b[39m,\u001b[38;5;241m0\u001b[39m],\u001b[38;5;241m2\u001b[39m), \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124myr\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     10\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpredicted age using your neural network and Keras-estimated parameters: \u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28mround\u001b[39m(yout_k[\u001b[38;5;28mlen\u001b[39m(NpL_Keras)\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m][\u001b[38;5;241m0\u001b[39m,\u001b[38;5;241m0\u001b[39m], \u001b[38;5;241m2\u001b[39m), \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124myr\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "Cell \u001b[1;32mIn[14], line 32\u001b[0m, in \u001b[0;36mANN\u001b[1;34m(x, NpL, Nfx, Wts, bias, ActivFun)\u001b[0m\n\u001b[0;32m     29\u001b[0m y \u001b[38;5;241m=\u001b[39m []\n\u001b[0;32m     30\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m iL \u001b[38;5;129;01min\u001b[39;00m np\u001b[38;5;241m.\u001b[39marange(\u001b[38;5;28mlen\u001b[39m(NpL)):\n\u001b[0;32m     31\u001b[0m     \u001b[38;5;66;03m## parameters\u001b[39;00m\n\u001b[1;32m---> 32\u001b[0m     WL \u001b[38;5;241m=\u001b[39m \u001b[43mWts\u001b[49m\u001b[43m[\u001b[49m\u001b[43miL\u001b[49m\u001b[43m]\u001b[49m\n\u001b[0;32m     33\u001b[0m     bL \u001b[38;5;241m=\u001b[39m bias[iL]\n\u001b[0;32m     34\u001b[0m     \u001b[38;5;66;03m## multiplication\u001b[39;00m\n\u001b[0;32m     35\u001b[0m     \u001b[38;5;66;03m## make sure that the operation is correct for n individual points.\u001b[39;00m\n\u001b[0;32m     36\u001b[0m     \u001b[38;5;66;03m## the dimension of zL should be nL x n. Since bL is nL x 1, use np.tile to overcome this issue.\u001b[39;00m\n\u001b[0;32m     37\u001b[0m     \u001b[38;5;66;03m#print('WL shape:', WL.shape)\u001b[39;00m\n\u001b[0;32m     38\u001b[0m     \u001b[38;5;66;03m#print('yLm1 shape:', yLm1.shape)\u001b[39;00m\n\u001b[0;32m     39\u001b[0m     \u001b[38;5;66;03m#print('bL shape:', bL.shape)\u001b[39;00m\n",
      "\u001b[1;31mIndexError\u001b[0m: list index out of range"
     ]
    }
   ],
   "source": [
    "param_keras = model.get_weights()\n",
    "len_par = len(param_keras)\n",
    "wts_keras = [param_keras[i].T for i in np.arange(0, len_par, 2)]\n",
    "bias_keras = [param_keras[i].reshape(param_keras[i].shape[0], 1) for i in np.arange(1, len_par, 2)]\n",
    "ActivFun_Keras = ['relu', 'relu', 'relu', 'linear']\n",
    "NpL_Keras = [16,32,16,1]\n",
    "Nfx = 8\n",
    "yout_k, zout_k = ANN(x = mydata.T, NpL = NpL_Keras, Nfx = Nfx, Wts = wts_keras, bias = bias_keras, ActivFun = ActivFun_Keras)\n",
    "print(\"predicted age using Keras-built network: \", round(predictions[0,0],2), \"yr\")\n",
    "print(\"predicted age using your neural network and Keras-estimated parameters: \", round(yout_k[len(NpL_Keras)-1][0,0], 2), \"yr\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "474848b7-26c0-4fed-9b73-445ce75f6c9e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3\n",
      "4\n"
     ]
    }
   ],
   "source": [
    "print(len(wts_keras))\n",
    "#print(Wts[0])\n",
    "print(len(NpL_Keras))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36247469-d846-4830-a6ea-ed55b915e7af",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
